# LAB1 实现指导

这次我们实现的是编译的第一步——词法分析。

词法分析的作用是将输入的字节流/字符流转换成单词（Token）序列，本质上就是使用一组正则表达式不断地匹配输入流，在每次匹配出结果之后输出当前结果，并且返回开始状态准备匹配下一个。

~~嗯……我其实挺想用允许自动化工具的，可是那样这个实验不就没意义了吗！所以，下面还是要从原理讲起！~~

## 基础原理

举个例子！比如咱们现在有一个语法，其中只有四种单词，长下面这样 _（顺便一提，这种风格的 EBNF 你们之后还会见到很多次……）_：

```plaintext
Ident  -> [Aa] [Aa01]*  // 标识符
Number -> [01]+         // 数字
Add    -> '+'           // 加号
WS     -> ' '+          // 空白（之后会被丢弃）
```

那么我们可以构造这样一个自动机：

![简单的自动机](../res/azuki-guidebook-lex-basic.png)

其中的虚线代表我们不读入这个字符，只获取它的值。这种操作一般称作为 `unread`（读入之后再放回去）或者 `peek`/`lookahead`（偷看输入的下一个值）。

看起来没啥问题。你可以自己模拟运行一下，看看这个自动机是不是将每个合法的句子都转换成了对应的单词序列。

那么如果我们再加一种单词，关键字 `KW -> 'AA'` 呢？自然，我们可以先把 `Start -A-> X -A-> Y --> /KW/` 这条规则加到 NFA 里面，然后简化成 DFA，最终大概长这样：

![复杂的自动机](../res/azuki-guidebook-lex-extra.png)

——作为自动化工具生成的结果没啥问题，但是关键字多一些的话手工实现就比较难了。所以，在手工实现的时候我们一般采取下面这种方法：

注意到关键字 `AA` 是一个合法的标识符，那么我们完全可以在识别完标识符之后再去判断它等不等于 `AA`。于是，我们可以这么设计自动机：

![不那么复杂的自动机](../res/azuki-guidebook-lex-extra-simp.png)

是不是看起来好多了？

实际上，这种操作是广泛存在的——绝大多数编程语言的关键字都被设计成了合法的标识符，以此来降低词法分析的设计难度（以及自动机的状态数）。类似地，很多语言还会尽可能将单词的起始字符设计成不重合的，这样也可以尽量减少词法分析的难度。

> 你问例外？Java 最近新加了个关键字叫 `non-sealed`，设计者估计脑子有泡……

## 上手编写


